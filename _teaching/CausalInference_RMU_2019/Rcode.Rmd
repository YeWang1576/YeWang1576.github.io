---
title: "Quant II"
subtitle: "TSCS Data Estimation"
author: "Ye Wang"
date: "3/28/2018"
output: beamer_presentation

---




# Example
```{r assignment, echo=FALSE}
rm(list=ls())

# set parameters
N <- 100 # number of workers
Y0 <- abs(rnorm(N, 5, 1))
TE <- abs(rnorm(N, 1, 1))
ATE <- mean(TE)
Y1 <- Y0 + TE

# Bernoulli randomization
D <- rep(0, N)
p <- 0.5
for (i in 1:N){
  D[i] <- rbinom(1, 1, p)
}
sum(D)

# complete randomization
D <- rep(0, N)
Ntr <- 50
Nco <- N - Ntr
D[sample(1:N, Ntr)] <- 1
sum(D)
Y <- Y1*D + Y0*(1-D)

HT_c_real <- mean(Y[D==1]) - mean(Y[D==0])
cat("ATE =", ATE, "\n")
cat("HT estimate =", HT_c_real, "\n")

sim_data <- data.frame(Y, D, Y1, Y0, TE)
```

```{r unbiasedness, echo=FALSE}
nboots <- 1000
HT_c <- rep(NA, nboots)
for (i in 1:nboots){
  D.new <- rep(0, N)
  D.new[sample(1:N, Ntr)] <- 1
  Y.new <- Y1*D.new + Y0*(1-D.new)
  HT_c[i] <- sum(Y.new * D.new) / Ntr - sum(Y.new * (1-D.new)) / Nco
}
cat("ATE =", ATE, "\n")
cat("HT estimate =", mean(HT_c), "\n")
cat("The standard deviation of the HT estimate =", sd(HT_c), "\n")


HT1_b <- rep(NA, nboots)
HT2_b <- rep(NA, nboots)
for (i in 1:nboots){
  D.new <- rep(0, N)
  for (j in 1:N){
    D.new[j] <- rbinom(1, 1, p)
  }
  Y.new <- Y1*D.new + Y0*(1-D.new)
  HT1_b[i] <- sum(Y.new * D.new) / Ntr - sum(Y.new * (1-D.new)) / Nco
  HT2_b[i] <- sum(Y.new * D.new) / sum(D.new) - sum(Y.new * (1-D.new)) / sum(1-D.new)
}
cat("ATE =", ATE, "\n")
cat("HT estimate with expected ratio =", mean(HT1_b), "\n")
cat("The standard deviation of the HT estimate with expected ratio =", sd(HT1_b), "\n")
cat("HT estimate with real ratio =", mean(HT2_b), "\n")
cat("The standard deviation of the HT estimate with expected ratio =", sd(HT2_b), "\n")


```


```{r inference, echo=FALSE}
# Fisher inference
nboots <- 1000
ATE_null <- rep(NA, N)
for (i in 1:nboots){
  D.new <- rep(0, N)
  D.new[sample(1:N, Ntr)] <- 1
  ATE_null[i] <- mean(Y[D.new==1]) - mean(Y[D.new==0])
}
hist(ATE_null, breaks = 20, freq = 0)
lines(density(ATE_null), lty = "dotted")
abline(v = HT_c_real, col = "red")
pvalue <- sum(HT_c[1] < ATE_null) / length(ATE_null)
cat("The p-value under Fisher randomization test is ", pvalue, "\n")

# Neyman inference


```

```{r boot, echo=FALSE}
nboots <- 1000
HT_boots <- rep(NA, nboots)
for (i in 1:nboots){
  b_data <- sim_data[sample(1:N, N, replace = 1), ]
  HT_boots[i] <- mean(b_data[b_data$D==1, "Y"]) - mean(b_data[b_data$D==0, "Y"])
}
boot_95CI <- sort(HT_c_real - quantile(HT_boots - HT_c_real, c(0.025, 0.975)))

```


```{r regression, echo=FALSE}
require(sandwich)
Y1_s <- Y[D==1]
Y0_s <- Y[D==0]
S1 <- sum((Y1_s - mean(Y1_s))^2) / (length(Y1_s) - 1)
S0 <- sum((Y0_s - mean(Y0_s))^2) / (length(Y0_s) - 1)
se_exp <- S1 / length(Y1_s) + S0 / length(Y0_s)
reg_exp <- lm(Y~D, data = sim_data)
summary(reg_exp)
X_reg <- cbind(rep(1, length(Y)), D)
se_reg <- vcovCL(reg_exp, type = "HC2")
neyman_95CI <- c(-1.96*sqrt(se_exp), 1.96*sqrt(se_exp)) + HT_c_real
cat("HT estimate is", HT_c_real, "and regression estimate is", coef(reg_exp)[2], "\n")
cat("Neyman variance is", se_exp, "and regression variance is", se_reg[2,2], "\n")
cat("Asymptotic 95% confidence interval is", neyman_95CI, "\n")
cat("Bootstrap 95% confidence interval is", boot_95CI, "\n")

```


```{r non-compliance, echo=FALSE}
rm(list=ls())

# set parameters
N <- 200 # number of workers
D0 <- D1 <- rep(0, N)
D0[1:80] <- D1[1:80] <- 1
D1[121:200] <- 1

Y0 <- abs(rnorm(N, 5, 1))
TE <- abs(rnorm(N, 1, 1))
ATE <- mean(TE)
LATE <- mean(TE[121:200])
Y1 <- Y0 + TE

Z <- rep(0, N)
Ntr <- 100
Nco <- N - Ntr
Z[sample(1:N, Ntr)] <- 1
D <- D1*Z + D0*(1-Z)
Y <- Y1*D + Y0*(1-D)

ITT <- mean(Y[Z==1]) - mean(Y[Z==0])
cat("ATE =", ATE, "\n")
cat("LATE =", LATE, "\n")
cat("ITT effect =", ITT, "\n")

pi_a <- sum(D == 1 & Z == 0) / sum(Z == 0)
pi_n <- sum(D == 0 & Z == 1) / sum(Z == 1)
pi_c <- (sum(D == 1 & Z == 1) - pi_a*sum(Z == 1)) / sum(Z == 1)
cat("The percentage of alwayers-takers is", pi_a, ", the percentage of never-takers is", pi_n, ", the percentage of compliers is", pi_c, "\n")

Wald <- ITT/(mean(D[Z==1]) - mean(D[Z==0]))
cat("The estimate of LATE is", Wald, "\n")

```


```{r moderatorDGP, echo=FALSE}
rm(list=ls())

# set parameters
N <- 100 # number of workers
N_m <- 50
N_f <- N - N_m
N_h <- 40
N_nh <- N - N_h
gender <- rep(0, N)
gender[1:50] <- 1
hs <- rep(0, N)
hs[c(1:10, 51:80)] <- 1

Y0 <- abs(rnorm(N, 5, 1))
TE <- abs(rnorm(N, 1, 1)) + 0.2*gender + 0.3*hs + 0.5*gender*hs
ATE <- mean(TE)
CATE_m <- mean(TE[gender == 1])
CATE_f <- mean(TE[gender == 0])
CATE_h <- mean(TE[hs == 1])
CATE_nh <- mean(TE[hs == 0])
Y1 <- Y0 + TE

# complete randomization
D <- rep(0, N)
Ntr <- 50
Nco <- N - Ntr
D[sample(1:N, Ntr)] <- 1
Y <- Y1*D + Y0*(1-D)

HT_real <- mean(Y[D==1]) - mean(Y[D==0])
cat("ATE =", ATE, "\n")
cat("CATE for male =", CATE_m, "\n")
cat("CATE for female =", CATE_f, "\n")
cat("CATE for high school graduates =", CATE_h, "\n")
cat("CATE for non-high school graduates =", CATE_nh, "\n")

cat("HT estimate =", HT_real, "\n")

sim_data <- data.frame(Y, D, gender, hs, Y1, Y0, TE)

```

```{r moderator, echo=FALSE}
nboots <- 1000
ATE_est_reg <- ATE_est_reg_lin <- ATE_est_exp <- ATE_est_blk <- rep(NA, N)
HT <- rep(NA, N)
for (i in 1:nboots) {
  D.new <- rep(0, N)
  D.new[sample(1:N, Ntr)] <- 1
  Y.new <- Y1*D.new + Y0*(1-D.new)
  reg_exp <- lm(Y.new~D.new+gender+hs)
  ATE_est_reg[i] <- coef(reg_exp)[2]
  # demeaned.gender <- gender - mean(gender)
  # demeaned.hs <- hs - mean(hs)
  # lin_reg_exp <- lm(Y.new~D.new*demeaned.gender+D.new*demeaned.hs)
  # ATE_est_reg_lin[i] <- coef(lin_reg_exp)[2]
  ATE_est_exp[i] <- mean(Y.new[D.new==1]) - mean(Y.new[D.new==0])
  CATE_mh_est <- mean(Y.new[D.new==1 & gender==1 & hs==1]) - mean(Y.new[D.new==0 & gender==1 & hs==1])
  CATE_fh_est <- mean(Y.new[D.new==1 & gender==0 & hs==1]) - mean(Y.new[D.new==0 & gender==0 & hs==1])
  CATE_mnh_est <- mean(Y.new[D.new==1 & gender==1 & hs==0]) - mean(Y.new[D.new==0 & gender==1 & hs==0])
  CATE_fnh_est <- mean(Y.new[D.new==1 & gender==0 & hs==0]) - mean(Y.new[D.new==0 & gender==0 & hs==0])
  if (is.na(CATE_mh_est) | is.na(CATE_fh_est) | is.na(CATE_mnh_est) | is.na(CATE_fnh_est)){
    next("Overlapping assumption is violated!")
  }
  ATE_est_blk[i] <- CATE_mh_est * (sum(gender==1 & hs==1) / length(Y.new)) + 
    CATE_fh_est * (sum(gender==0 & hs==1) / length(Y.new)) + 
    CATE_mnh_est * (sum(gender==1 & hs==0) / length(Y.new)) + 
    CATE_fnh_est * (sum(gender==0 & hs==0) / length(Y.new))
}

cat("The average value of the regression estimate is", mean(ATE_est_reg), "\n")
cat("The average value of the group-mean-difference estimate is", mean(ATE_est_exp), "\n")
cat("The average value of the blocking estimate is", mean(ATE_est_blk, na.rm = 1), "\n")
cat("The ATE is", ATE, "\n")

```

```{r cf, echo=FALSE}
require(grf)
n = 2000; p = 10
X = matrix(rnorm(n*p), n, p)
X.test = matrix(0, 101, p)
X.test[,1] = seq(-2, 2, length.out = 101)
# Train a causal forest.
W = rbinom(n, 1, 0.4 + 0.2 * (X[,1] > 0))
Y = pmax(X[,1], 0) * W + X[,2] + pmin(X[,3], 0) + rnorm(n)
tau.forest = causal_forest(X, Y, W)
# Estimate treatment effects for the training data using out-of-bag prediction.
tau.hat.oob = predict(tau.forest)
hist(tau.hat.oob$predictions)
```

```{r data-loading, echo=FALSE}
# Set up data
d <- read.csv("title7_race.csv")
d$LiberalOutcome <- as.integer(d$case_outcome == 'Liberal')
d$Female <- as.integer(d$gender_judge == 'Female')
d$LiberalLowerDirection <- as.integer(d$lower_dir == 'Liberal')
d$Republican <- as.integer(d$party_judge == 'Republican')
d$Experienced <- as.integer(d$jud_experience == 'Experienced')
d$Minority <- as.integer(d$race_judge != 'White')
d$jcs <- d$jcs - min(d$jcs)
d$confirm_yr <- d$confirm_yr - min(d$confirm_yr)
d$Age <- d$dec_year - d$year_birth

case.order <- unique(d$order) # collapse covariates on cases
median.ideo <- unlist(lapply(case.order, function(x) median(d[d$order == x,]$jcs)))
repub.majority <- as.integer(unlist(lapply(case.order, function(x) sum(d[d$order == x,]$Republican) > 1)))
has.minority <- as.integer(unlist(lapply(case.order, function(x) sum(d[d$order == x,]$Minority) > 0)))
maj.experienced <- as.integer(unlist(lapply(case.order, function(x) sum(d[d$order == x,]$Experienced) > 1)))
has.woman <- as.integer(unlist(lapply(case.order, function(x) sum(d[d$order ==x,]$gender_judge == 'Female') > 0)))
liberal.lower.direction <- unlist(lapply(case.order, function(x) unique(d[d$order == x,]$LiberalLowerDirection)))
median.age <- unlist(lapply(case.order, function(x) median(d[d$order == x,]$Age)))
median.confirmation.year <- unlist(lapply(case.order, function(x) median(d[d$order == x,]$confirm_yr)))
ideo.range <- unlist(lapply(case.order, function(x) diff(range(d[d$order == x,]$jcs))))
minorityXmedianIdeo <- median.ideo * has.minority
liberalOutcome <- unlist(lapply(case.order, function(x) unique(d[d$order == x,]$LiberalOutcome)))

# 6 covariates in total
d.new <- data.frame(
  case.order = case.order,
  median.ideo = median.ideo,
  repub.majority = repub.majority,
  has.minority = has.minority,
  maj.experienced = maj.experienced,
  median.age = median.age,
  liberal.lower.direction = liberal.lower.direction,
  has.woman = has.woman,
  liberalOutcome = liberalOutcome)

trt <- d.new$has.woman == 1

means <- apply(d.new[,-8], 2, function(x) tapply(x, trt, mean))
sds <- apply(d.new[-8], 2, function(x) tapply(x, trt, sd))
t.p <- apply(d.new[, -8], 2, function(x) t.test(x[trt], x[!trt])$p.value)
suppressWarnings(ks.p <- apply(d.new[, -8], 2, function(x) ks.test(x[trt], x[!trt])$p.value))
rownames(means) <- rownames(sds) <- c("Treated", "Control")
```

# View Initial Balance
\footnotesize
```{r}
initial.balance <- round(t(rbind(means,t.p)),digits=3)[c(2:8),]
initial.balance
```

```{r NN-formula, echo=FALSE}
library(MatchIt)
matching.formula <- as.formula('has.woman ~ 
    median.ideo + median.age + repub.majority +
     has.minority + maj.experienced + liberal.lower.direction')
```

# Nearest Neighbor Matching
\footnotesize
```{r NN-matching, echo=FALSE}
matched.NN <- matchit(matching.formula, method="nearest", data = d.new)
d.NN <- match.data(matched.NN)
t.NN <- apply(d.NN[, c(2:7)], 2, function(x) t.test(x[d.NN$has.woman==1], x[d.NN$has.woman==0])$p.value)
result.NN <- summary(matched.NN)[3][[1]][-1,]
result.NN <- data.frame(cbind(result.NN, t.NN))
result.NN[,c(1:2,8)]
```

```{r p-score, echo=FALSE}
p.model <- glm(trt ~ median.ideo + median.age + 
                 repub.majority + has.minority +
                 maj.experienced + 
                 liberal.lower.direction,
               d.new, family = "binomial")

pscore.logit <-  predict(p.model, type = "response")
hist(pscore.logit)
```

```{r ps-matching, echo=FALSE}
d.ctl <- subset(d.new, has.woman == 0)
pscore.logit.ctl <- pscore.logit[!trt]
pscore.logit.trt <- pscore.logit[trt]

d.trt <- subset(d.new, has.woman == 1)
matches <- sapply(pscore.logit.trt, function(x) which.min(abs(pscore.logit.ctl-x)))
d.trt <- rbind(d.trt, d.ctl[matches, ])
plot(c(pscore.logit.trt, pscore.logit.ctl[matches]), jitter(rep(c(1, 0), c(N,N))), axes = F, ylab= "Treatment and Control", 
     xlab = "Propensity Score")
axis(1)
```

```{r IPW, echo=FALSE}
base.model <- lm(liberalOutcome ~ has.woman + median.ideo + median.age + repub.majority + has.minority + maj.experienced + 
                   liberal.lower.direction, d.new)

ipw.logit <- trt + (1 - trt)/(1 - pscore.logit)

ipw.logit.mod <- lm(liberalOutcome ~ has.woman+median.ideo + median.age +repub.majority+has.minority + 
                      maj.experienced+liberal.lower.direction, d.new, weights=ipw.logit)
summary(base.model)
summary(ipw.logit.mod)
```


```{r ebal, echo=FALSE}
library(ebal)
treatment <- d.new$has.woman
X <- d.new[, 2:7]
eb.out <- ebalance(Treatment=treatment, X=X)
balance_tab <- cbind(apply(X[treatment==1,], 2, mean), apply(X[treatment==0,], 2, weighted.mean, w=eb.out$w), apply(X[treatment==0,], 2, mean))
colnames(balance_tab) <- c("treated average", "weighted treated average", "control average")
balance_tab
```